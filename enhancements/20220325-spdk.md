# Reimplement Longhorn Engine with SPDK

## Summary

[SPDK](https://spdk.io) is a framework for building high performance storage applications.  SPDK has several features that allow it perform tasks similar to what the longhorn-engine needs currently.  

* [Block Devices](https://spdk.io/doc/bdev.html), or bdevs, are SPDK storage
devices that support reading and writing data in fixed-size blocks.  Bdevs can
be composed of other bdevs, and bdevs can also be stored in another bdev.   One
built in example of a bdev being composed of another bdev is the RAID 0 bdev. 
 

* [Logical volumes](https://spdk.io/doc/logical_volumes.html) is a feature in
SPDK which allows one large bdev to be broken up into multiple smaller bdevs. 
The large bdev has a _logical volume store_ which has information about each
_logical volume_ contained within it.  The _logical volume store_ has a table
of blocks for each _logical volume_; the data in a volume isn't necessarily
continguous.  Also, the data in a volume can be thinly provisioned;  Like the
current longhorn-engine, a thinly provision volume starts as a virtual device
consisting of all zeroes.  When data is written to the volume, unused blocks
for the data are used and the volume's table of blocks is updated. 

Also, a logical volume supports snapshots like the longhorn-engine.  When data
is read from a logical volume, for each block that is being read, that block
number is looked up in the volume's table.  If the block is in the table, the
block is read from the block specified.  If the block is not specified and the
logical volume has a snapshot, it will look for the block in the snapshot.
This will continue until either the data is found or a virtual zero logical
volume is reached.

A logical volume has the ability to perform snapshots which is a feature that
is used as the basis for rebuilding, backups, and snapshots in general in the
current longhorn engine.  Logical volumes are stored sparsely their parent's
bdev similar to how the existing volume files are filesystem level sparse
files.   

* [NVMe over Fabrics](https://spdk.io/doc/nvmf.html)

Any bdev can be made available as an NVMe over Fabrics target.  SPDK
can internally make an NVMe over Fabrics target available as an bdev.
For longhorn, a replica will make its logical volume available as an
NVMe over Fabrics targets, and the longhorn bdev will _mount_ it as a
bdev within SPDK.  This will allow a longhorn bdev to forward I/O
operations to a remote logical volume.

Also, a virtual longhorn volume can be made available as an NVMe over
Fabrics target.  Linux can connect to these targets and make them
available as a block device.  The `nvme` command can query and connect
to NVMe over Fabrics targets, which makes them available as NVMe block
devices to the Linux operating system (i.e.  `/dev/nvmeXn1`). 


### Related Issues

The URL For the related enhancement issues in Longhorn repo.

## Motivation

### Goals

* Use SPDK to improve performance
* Use SPDK to scale better

### Non-goals [optional]

* Providing the ability to continue to use the same
`/var/lib/liblonghorn` data path.
* Continuing to support qcow2 files.
* Continuing to support multiple engine versions concurrently.

## Proposal

Create a new longhorn bdev in SPDK.  The longhorn bdev will be created 
with a list of _replicas_ which are local and/or remote logical volumes.  
The longhorn bdev is exposed over NVME over Fabrics.  The system will
connect to the longhorn bdev over NVME over Fabrics, and it will be available
as a device file.

The longhorn bdev will handle I/O operations in a way such that all of the 
replicas are in sync.  Every write operation is performed on every connected
replica.  The longhorn bdev internally has a bdev for each replica.  A local
replica is used directly; a remote replica is an NVME over Fabrics bdev.

The longhorn bdev will write all write operations to all replicas; it will 
choose a replica to read from in a round-robin manner.  As will the current
longhorn-engine, a timeout can occur with each operation on replicas, 
which will remove than replica from the list of replicas.


### User Stories

For the most part, the user experience between longhorn with SPDK should
be the same as longhorn without SPDK.

#### Storage Configuration

Before SPDK, `/var/lib/longhorn` was used for storage and add additional disks
as paths.  In all cases, the disk paths are formatted and mounted disks which
can also be used for other things.

With SPDK, a full disk can be used.  Each disk will be specified as a device
file. 

### User Experience In Detail

### API changes

The CRDs for longhorn will change slightly because of the new architecture.
The new design eliminates the instance manager so the InstanceManager CRD isn't
necessary.  Some of the specific fields in th Engine and Replica CRDs will need
to be changed.


## Design

### Implementation Overview

A new longhorn bdev will be added to SPDK.  This bdev will be a composite bdev
of one or more replica bdevs.  Changing Longhorn's data plane will be a
significant change.  One significant departure from the current design is that
the logical volume store that will be used for longhorn volumes supports
multiple volumes within one running instance of SPDK.  This will reduce the 
number of processes running on the cluster.  Previously, every volume required
a longhorn engine process.

#### SPDK Programming Model

SPDK's programming model rather different than the existing
longhorn-engine.  The current longhorn-engine uses goroutines
extensively.  For SPDK, an event driven model is used.  By default, 
one actual thread runs on one core of the system's processor.  This 
thread continuous polls for events, i.e. file descriptors becoming readable.
When an event occurred, callbacks registered for that event are called.

Callbacks should typically execute quickly.  In most cases, they will either
finish handling the event or call another function cannot be performed 
immediately.  This function will take another callback.  The original 
callback will finish, relinquishing control the polling code, which should
eventually receive the event that another callback is awaiting.

Will the programming model, it's not possible to just do things
step-by-step.  Almost everything requires a series of callbacks.

By default, SPDK runs as just one thread.  However, it is possible to increase
the number of threads.  In this case, multiple threads will be polling for
events and executing the callbacks within different threads.  Longhorn 
specific changes should be able to work under different threading conditions.

Also, while there are different threading configuration for SPDK,
SPDK internally assigns everything being executed to a virtual thread 
which doesn't correspond to the actual thread that the process is executing
in.    


#### Longhorn Volume Bdev

The longhorn volume bdev will be a virtual volume that relays I/O operations
to a set of _replicas_.  

#### Replica

A replica will be a logical volume in a logical volume store. 

#### Operations

##### I/O

* Read - The longhorn volume bdev will chose of the replicas to read from.
* Write - The longhorn volume bdev will write to all of the replicas.

##### Snapshot

Snapshots need to be performed such that all replicas contain the same
data when the snapshot occurs.

1. Signal all the I/O threads to stop performing I/O.
2. When all the writing threads are stopped, call snapshot API on 
all the local replicas and issue a remote JSON-RPC call to perform a
snapshot on the remote replicas.
3. Resume the I/O threads.

##### Adding new replica

When a new replica is added to an existing volume, it 

1. A snapshot operation is performed on the current set of replicas in
the volume with an auto generated snapshot name.
2. The new replica is added to the list of replicas as a _write only_ replica.
3. The new replica queries one of the existing replicas to get the list of
snapshots and the allocated blocks in each snapshot with JSON-RPC.
4. The replica being queried assembles the snapshot info and makes each
snapshot available over NVMe over Fabrics and sends this information to
the new replica over JSON-RPC.
5. The new replica recreates each snapshot by creating new logical volumes,
registering the remote NVMe over Fabrics target can copying just the relative 
blocks.
6. The snapshot logical volumes on the new replica are linked together.
7. The _write only_ replica is changed to _read/write_.

##### Backups

Using the S3 REST API from SPDK is somewhat impractical.  The S3 REST API
is usually used with higher level programming language than C.  Also, 
integrating an external network connection into the SPDK polling
mechanism could affect other operations.  Because of this, SPDK will provide
access to a volume so that a backup implementation in golang could 
perform the backup outside of SPDK.

Within SPDK, backup functionality consists of:
1. Performing a snapshot
2. Making that snapshot available over NVMe-oF.

The external backup program will mount the NVMe-oF target for the snapshot
and perform the backup.

For a restore, we need to create a new volume with the contents of the
backup.  In scenario, SPDK will:
1. Create a new volume.
2. Make that volume available over NVMe-oF.

Then an external restore program will mount the NVMe-oF target and copy the 
data from the external backup to the volume.

#### Deployment and Integration

SPDK with longhorn support will have a JSON-RPC API for creating and managing
longhorn volumes.   Because each SPDK instance will manage both multiple 
volumes and multiple replicas, the current implementation with two instance
managers on each node to manage the engine and replicas processes is not 
needed. 

The longhorn-manager will be able to communication with SPDK directly.
With this change, the following components will be removed:
* Longhorn instance manager
* Longhorn engine (longhorn-engine controller)
* Longhorn replica

Also longhorn will use NVMe over Fabrics to create the block device instead
of iSCSI.  In order to use NVMe over Fabrics to connect to a remote device,
the `nvme_tcp` kernel module needs to be installed on the node. There is
a sysfs interface which can be used to connect to an NVMe over Fabrics
target.  Using NVMe over Fabrics eliminates the following following
components from longhorn:
* iscsid/isciadm from the node.
* tgt and liblonghorn


##### Security

The JSON-RPC API by default is only available over the `/var/tmp/spdk.sock`
'Unix domain socket.   The code can be extended to support JSON-RPC over
an TCP socket.  The TCP socket would accept a stream of JSON-RPC commands and
return results.  The TCP socket is necessary for performing operations
on the longhorn bdev volume that require functionality beyond the read and
write provided by NVMe over Fabrics.  For example, snapshots require the 
communication with each remote replica and rebuilding requires two replicas
to be able to communicate with each other.  Also, the TCP socket can be the 
way the longhorn-manager starts replicas and volumes.

The TCP socket is a security consideration.  Longhorn is in the process of
using mTLS to encrypt and authentication gRPC communication among components.
The communication between SPDK instances could potentially use openssl.
It may be possible to use mTLS with in C.  Also, the longhorn-manager to SPDK
communication could use a separate program that translates existing
gRPC calls, which will be encrypted with mTLS, to JSON-RPC over the Unix domain
socket.

NVMe over Fabrics is being used without authentication and encryption over
TCP.  NVMe over Fabrics can use Diffie-Hellman HMAC-CHAP for authentication
and always use TLS.  




### Test plan

The current longhorn-engine is able to use locks and r/w locks to synchronize
state.  With SPDK, the writing threads are notified that they need to pause
in order to perform an operation.  Because of this programming model, it is 
important to verifying that we can maintain consistency when performing 
operations that require the data on the replicas to be synchronized before 
performing.

Because of this, it is important to develop tests that stress the operations
that require synchronizing.  Performing these operation while writing is 
important.  Golang will be used to develop tests for this.  Python
is currently used for tests but the global interpreter lock makes it 
difficult to use to develop tests to exercise concurrent scenarios. Golang
will allow tests to perform concurrent tasks easily.


### Upgrade strategy

This will represent a significant change to how longhorn is deployed and
how longhorn volumes are stored on disk.  Also, the longhorn has some custom
resources which will no longer make sense, like the instance manager.

One approach could be importing the exist hierarchy of sparse files from the
current longhorn-engine into logical volumes, perserving the sparseness of the
files.  The hierarchy can be linked together by assigning parent attribute.

## Note [optional]

Additional nodes.
